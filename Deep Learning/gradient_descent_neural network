#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sat Dec 29 21:06:10 2018

@author: nj

"""
import numpy as np

#using sigmoid as the activation function
#defining sigmoid function for activation
def sigmoid(x):
    return 1/(1+np.exp(-x))

#derivative of the sigmoid function
def sigmoid_prime(x):
    return sigmoid(x) * (1 - sigmoid(x))


#defining the learning rate parameter
learnrate = 0.5

#input data
x = np.array([1,2,3,4])

#target
y = np.array([0.5])

#initial weights
w = np.array([0.5, -0.5, 0.3, 0.1])

#node's linear combination of i/p and o/p
h = x[0] * w[0] + x[1] * w[1] + x[2] * w[2] + x[3] * w[3]

#o/p of neural network
nn_output = sigmoid(h)

#error of neural network
error = y - nn_output

#ouput gradient
output_grad = sigmoid_prime(h)
error_term = error * output_grad

#change in weights....
del_w = [ learnrate * error_term * x[0],
          learnrate * error_term * x[1],
          learnrate * error_term * x[2],
          learnrate * error_term * x[3]]

print('Neural network output:')
print(nn_output)
print('Amount of error:')
print(error)
print('change in weights:')
print(del_w)

    
    



